1. FILTERING,MUTATION -DPLY PACKAGES


install.packages("dplyr")
library(dplyr)
library(MASS)
glimpse(survey)
head(survey)
summary(survey)
dplyr::select(survey, Clap:Age)
dplyr::select(survey, Clap:Age, -M.I)
survey %>% dplyr::mutate(Sex, dif = Wr.Hnd - NW.Hnd)
?survey
survey %>% dplyr::filter(Age > 22)
survey %>% dplyr::filter(Age > 22) %>% group_by(Clap)
survey %>% dplyr::filter(Height > 170) %>% summarize(avg = mean(Age))
survey %>% dplyr::filter(Height > 170) %>% summarize(avg = mean(Pulse, na.rm = TRUE))
survey %>% dplyr::filter(Age > 22) %>% dplyr::arrange(Age)
survey %>% dplyr::filter(Age > 22) %>% dplyr::arrange(desc(Age))



2. DECISION TREE CLASSIFIER
hp<-read.csv("C:/Users/HP/Desktop/dataset/Data Mining Lab/r/diabetes.csv")
d=hp$gender
e=hp$age
f=hp$hypertension
g=hp$heart_disease
h=hp$smoking_history
i=hp$bmi
j=hp$HbA1c_level
k=hp$blood_glucose_level
l=hp$diabetes
sapply(hp,class)
install.packages("party")
library(party)
sapply(hp,class)
d<-factor(d)
h<-factor(h)
model=ctree(formula = l ~ d + e + f + g + h + i + j + k ,data= hp,controls =ctree_control(minsplit = 20,minbucket = 7))
plot(model)



3.MULTIPLE LINEAR REGRESSION

 install.packages("mlbench")
install.packages("dplyr")
install.packages("ggplot2")
install.packages("reshape2")
install.packages("caTools")
library(mlbench)
library(dplyr)
library(ggplot2)
library(reshape2)
library(caTools)
dat = read.csv("C:/Users/HP/Desktop/dataset/Data Mining Lab/r/boston_housing.csv")
print(dat)
str(dat)
summary(dat)
split=sample.split(dat,SplitRatio = 0.70)
train=subset(dat,split==TRUE)
test=subset(dat,split==FALSE)
model=lm(medv~crim+rm+tax+lstat,dat=train)
summary(model)
y=predict(model,test)
head(y)
error=(test$medv-y)
rmse=sqrt(mean(error)^2)
rmse
ggplot(data=test,aes(medv,y)) +geom_point(alpha=0.5) +stat_smooth(aes(colour='black'))+xlab('Actual value of medv') + ylab('Predicted value of medv')+theme_bw()



4.SIMPLE LINEAR REGRESSION

data = read.csv("C:/Users/HP/Desktop/dataset/Data Mining Lab/r/Student_Marks.csv")
print(data)
training = data[seq(1, nrow(data), 2), ]
verification = data[seq(2, nrow(data), 2), ]
time_study = training[, 3]
Marks = training[, 2]
verification_time_study = verification[, 3]
verification_Marks = verification[, 2]
fit = lm(time_study ~ Marks)
mean_diff = mean(time_study - verification_time_study)
rmse = sqrt(sum((time_study - verification_time_study)^2) / length(time_study))
cat("Mean Difference:", mean_diff, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
a = data.frame(Marks =7)
result <- predict(fit, a)
print(result)





5. ASSOCIATION RULE MINING

install.packages("arules")
library(arules)
data("Groceries")
groceries.transactions<-as(Groceries,"transactions")
summary(groceries.transactions)
groceries_matrix<-as(Groceries,"matrix")
groceries_df<-as.data.frame(as(groceries_matrix,"matrix"))
print(groceries_df)
frequent_itemsets<-eclat(groceries.transactions,parameter = list(supp=0.005,maxlen=10))
rules<-ruleInduction(frequent_itemsets,transactions=groceries.transactions,confidence=0.1)
rhs_items<-c("whole milk","butter")
filtered_rules<-subset(rules,subset=rhs%in%rhs_items)
inspect(filtered_rules)
inspect(frequent_itemsets)
inspect(rules)




 6. hirarchial clustering
install.packages("dendextend")
library(dendextend)
install.packages("datasets")
data("USJudgeRatings")
install.packages("dendextend")
library(dendextend)
install.packages("datasets")
library(cluster)
distance <- dist(USJudgeRatings, method = "euclidean")
distance
mymodel <- agnes(distance, method = "ward")
plot(mymodel, main = "Agglomerative Hierarchical Clustering - USJudgeRatings")
groups <- cutree(mymodel, k = k)
output <- cbind(USJudgeRatings, groups)





7. k-means clustering 

seed<-read.csv("C:/Users/Lenovo/Downloads/seed(2) (1).csv")
model = kmeans(seed,3)
model
model$totss
model$size
model$centers
model$betweens
cluster =model$cluster
cluster
output =cbind(seed,cluster)
output





8. WORD CLOUD


install.packages('tm')
install.packages('wordcloud')
install.packages('SnowballC')
install.packages('RColorBrewer')
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
filePath<-"http://www.sthda.com/sthda/RDoc/example-files/martin-luther-king-i-have-a-dream-speech.txt"
text <- readLines(filePath)
docs <- Corpus(VectorSource(text))
inspect(docs)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,max.words=200, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, "Dark2"))



9.DECOMPOSITION
install.packages("ggfortify")
install.packages("tseries")
install.packages("forecast")
library(ggfortify)
library(tseries)
library(forecast)
data("AirPassengers")
AP<-AirPassengers
class(AP)
sum(is.na(A))
frequency(P)
cycle(AP)
plot(AP,xlab="Date",ylab="Passengers numbers(1000's)",main="Air Passenger numbers
from1949 to 1961")
autoplot(AP)+labs(x="Date",y="Passenger numbers(1000's"),title="Air Passengers from
1949to 1961")
boxplot(AP~cycle(AP),xlab = "Date",ylab="Passenger Numbers(1000's)",main="Monthly
AirPassengers Boxplot from 1949 to 1961")
decomposeAP<-decompose(AP,"multiplicative")
autoplot(decomposeAP)



1. VISUALISATION OF STUDENTS ADMISSION DATASET:
    a)import student dataset
    b)sheet 1- col:college
               row:s.no(count)
    c)sheet 2- col:state
               row:s.no(count)
    d)sheet 3- col: community
               row:s.no(count)
    e)sheet 4-col: hstlr/dayscholar
              row:s.no(count)

2.USING TABELAU & FIND THE CRITICAL AREAS OF IMPROVEMENT
 WITHIN THE COMPANY:
   
   a) import (superstore2017) dataset
   b) click orders -> col: sub-category
                      row:profit(sum)
                      label:profit(sum)


3.DATA BLENDING IN TABLEAU:    
    a) open MICROSOFT ACCESS -> COFFEE CHAIN dataset
        double click coffe chain -> add coffechain query +
                 fact table + loctn + product
    b)add database EXCEL -> add SAMPLE SUPER STORE dataset.
         double click orders
    c) sheet1- col: profit(sum)
               row:state
               label:profit(sum)
      LINK SYMBOL WILL APPEAR IN STATE


4.ANALYSIS OF STOCK DATA 2010-2013
    a) import STOCKS data -> double click stocks 2010-2013
    b) sheet1 -> col: date -> sort -> 2nd month
                 row: volume(sum)
                 label:volume
    c) sheet2 -> col: year(date)
                 row:company
                 filter: company[APPLE]
                 text:vol(count)
    d) sheet 3 -> col:date,date(twice),company
                  row:volume(SUM) -> r8 click ->quick table calculatn-> % diff
                  filter: company[BIOGEN]
                  label:vol (count)
    e)Dashboard -> shet1+sht2+sht3


5.VISUALIZATION OF STOCK AND FLIGHT DATASET:

  a) import FL8 dataset double click NEW UNION ->
         add stocks2010-2013 nd 2014
  b) sheet1 -> col: date, date
               row: close(AVG)
               filters:company(select all)
               colour:comp
  c) sheet2 -> col:carrier name
               row:min of delay per fl8 [AVG]
               filter:state[MN]
               colour:carrier name

6.VISUALIZATION OF SUPER STORE DATASET:
 
  a) import SUPERSTORE 2017 dataset
  b) r8 clk order date create cal values -> order day
      --> DATENAME('weekday',[Order Date]) -> ok
  c) shet 1 -> col: order day
               row: order date, sales (SUM)
               filter:date -> year ->2017 ->ok
               label:sales
               colour: order day

7. VISUALIZATION OF BAKERY DATASET:
   
  a) import BAKERY dataset
  b)r8 click date create cal field -> Weekday ->
       DATENAME('weekday',[Date])
  c)shet1 -> col: weekday
             row: transactn(SUM)
             colour:weekday
   fig:The sales of the product for the day of the week.

   d)shet2 -> col: weekday, item -> sort ->desecnding
              row:transaction(SUM)
              filter:weekday (MONDAY),item -> sort top 10 item
              colour:item
     fig:Maximum sale on Monday

8. DASHBOARD CREATION USING CAR DATASET:
      a)BAR
        Yaxis- Brand
        xaxis-Range-km
      b)pie chart
          price euro,brand
      c)donut
          seats,bodystyle
      d)dashboard

9. DASHBOARD CREATION USING INCOME DATASET:

      a)PIE CHART
          legend:race
          value:income
      b)BAR GRAPH - STACKED COLUMN CHART
           axis:income
           legend:educatn
           value:educatn
      c) GRAPH - CLUSTEERED COLUMN CHART
            axis:income
            legend:workclass
            value:income
      d)dashboard



POWER BI 


step1: we have to import(load) the zomato dataset in powerbi

step2: in the right side of data click the zamoto there will be displaying the attributes click the average cost of two values

step3: we have to visualize the condition.we have to click the gauge

step4:next method we have to clcik the city and visualize we have to use slice

step5: In the filter section the city is all has given we have to click that one and select all city and remove the two number from the city

step6: next method we have to select has online delivery in that we have to filter only yes and no and we have to remove the numerical

step7:Next method we have to select that has table booking and we have to filter the yes or no and we have to remove the numerical

step8:Next method we have to click the restaurant name votes and we have to use the visualize method to show and we have to filter method is condition

step9:we have to use format visualize and click the title and change the title as top restrataunt type and in the filter method --filter type as Top N and show items --top-10 and by value-sum of votes(from data drag and drop)and give apply filter

step10: cusines and click the filter method and remove the numerical values

step11: next method aggregating rating and give to visualize the card and down field label we have to change in the average

step12:next method click the sum of votes and give to visualize the card
step13:after complteting the visualization we ahve to make changes in the online delivery we have to click the yes and online table booking we have to give no.

step13:next method give the rating text and using filter remove the numerical

step14:in the up click the text box and change it into the times new roman font 40 and bold typed as retaraunt reviews

step15:change the title for average cost for two valuea as avrage cost in the format visualize

step16:change the restrauant type as top 10 restraunt type

step17: 1 condition we have to select the gurgan from city

step18: we have to find the average rating of barbeque nation in chennai---click the chennai city

step19: the avrage cost of afgani cusine in new delhi---- we have to clik the city as new delhi and cusinie as afgani


      
